{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdTxLFzE4sEirwRCeYTwHd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rootUJ99/hf_transformer_diffusers/blob/main/transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9zf2ObpSkX9C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dd457dc-299a-444b-f847-497b964d1e48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.16.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install safetensors torch huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import transformers\n",
        "print(transformers.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR7n8NvRlEOx",
        "outputId": "eadf962e-f95a-440c-febf-0cbe1b58e317"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pipeline -> dont know what is does"
      ],
      "metadata": {
        "id": "wWrcmoPFl9A5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(task=\"automatic-speech-recognition\", model=\"openai/whisper-small\", batch_size=2)"
      ],
      "metadata": {
        "id": "xB0kJ8RglbmU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generator(\"./sample_data/jfk.wav\")"
      ],
      "metadata": {
        "id": "O2rg9Z9PltEB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hW7rreE5l7Nt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator(\n",
        "    [\n",
        "        \"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\",\n",
        "        \"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/1.flac\",\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nw37rrI9mzsO",
        "outputId": "66800a4a-3aa0-4061-e3f3-cc419b1b0683"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'},\n",
              " {'text': ' He hoped there would be stew for dinner, turnips and carrots and bruised potatoes and fat mutton pieces to be ladled out in thick, peppered, flour-fattened sauce.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trying safe tensor (can skip this block for if just looking for )"
      ],
      "metadata": {
        "id": "m0uzmGOPg9c1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import safetensors\n",
        "import os\n",
        "import datetime\n",
        "from huggingface_hub import hf_hub_download\n",
        "from safetensors.torch import load_file\n",
        "import torch\n",
        "\n",
        "sf_model = hf_hub_download(\"gpt2\", filename=\"model.safetensors\")\n",
        "pt_model = hf_hub_download(\"gpt2\", filename=\"pytorch_model.bin\")\n",
        "\n",
        "start_sf = datetime.datetime.now()\n",
        "load_file(sf_model)\n",
        "loadtime_sf = datetime.datetime.now() - start_sf\n",
        "print(\"time taken by sf\", loadtime_sf)\n",
        "\n",
        "\n",
        "start_pt = datetime.datetime.now()\n",
        "torch.load(pt_model)\n",
        "loadtime_pt = datetime.datetime.now() - start_pt\n",
        "print(\"time taken by pt\", loadtime_pt)\n",
        "\n",
        "print(\"final time taken\", loadtime_pt/loadtime_sf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpB7kDfBg5Zf",
        "outputId": "4e6d97e8-5d0c-4adc-bb48-3e549610dfcb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time taken by sf 0:00:00.229092\n",
            "time taken by pt 0:00:04.190145\n",
            "final time taken 18.290228379864857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trying classification example"
      ],
      "metadata": {
        "id": "MN8p_8FImuuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier(\"here we go again for weath of the society\")\n",
        "classifier([\n",
        "\n",
        "    \"here is the cook, who cooks very good food\",\n",
        "    \"he just fucks everything up\"\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAxf4n8HmoqZ",
        "outputId": "028f51f5-38d7-4c18-d249-9ee32034ee4b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
            "pip install xformers.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9998283386230469},\n",
              " {'label': 'NEGATIVE', 'score': 0.9987642765045166}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genrator = pipeline(task=\"text-generation\")\n",
        "genrator(\"life is hard\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIz3Lwl0pCws",
        "outputId": "04f3ae6c-3e6f-4e0b-8fda-ed39ba156ebd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'life is hard to do because there is always a chance of some sort of injury or injury that could take place. I\\'m hoping we\\'ve kept our head in the game and our players do our jobs,\" said coach Ron Francis. \"We\\'ll make'}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Tokenization"
      ],
      "metadata": {
        "id": "1p0Mpe8OH3wn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "\n",
        "tokenizer(\"this is a magic mashroom\")\n",
        "\n",
        "pt_batch = tokenizer(\n",
        "    [\"this is magic mashroom\", \"you will go to paradise after eating it\"],\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    max_length=1024,\n",
        "    return_tensors=\"pt\"\n",
        "    )\n",
        "print(pt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBk75W3jBaXZ",
        "outputId": "53248151-17a2-4017-b708-8f3251cb98ef"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101, 10372, 10127, 17800, 10321, 16158, 39639,   102,     0,     0],\n",
            "        [  101, 10855, 11229, 11335, 10114, 27012, 10515, 59305, 10197,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### taking model"
      ],
      "metadata": {
        "id": "-Zs9ohSLIArf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "pt_model = AutoModelForSequenceClassification.from_pretrained(model)"
      ],
      "metadata": {
        "id": "6RICgezdGO9f"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pt_output = pt_model(**pt_batch)\n",
        "print(pt_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FnnLhvwG-Y4",
        "outputId": "d46b1d27-975a-4a72-d184-a4e4a134bfd8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SequenceClassifierOutput(loss=None, logits=tensor([[-1.1220, -1.6687, -0.5555,  0.6776,  2.1259],\n",
            "        [-0.4588, -0.6722, -0.1753,  0.2649,  0.6359]],\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train using pytorch"
      ],
      "metadata": {
        "id": "CJv2OttsIQOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "pt_pred = nn.functional.softmax(pt_output.logits, dim=-1)\n",
        "print(pt_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_BUFudgHOca",
        "outputId": "3356ba95-2d8f-4c3b-a6f2-0f7e133d9023"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0285, 0.0165, 0.0502, 0.1722, 0.7327],\n",
            "        [0.1222, 0.0987, 0.1622, 0.2519, 0.3651]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###saving model"
      ],
      "metadata": {
        "id": "4zfkM1_DJXdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pt_save_to_dir = \"./data\"\n",
        "tokenizer.save_pretrained(pt_save_to_dir)\n",
        "pt_model.save_pretrained(pt_save_to_dir)"
      ],
      "metadata": {
        "id": "2iAkJim5IUhr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### using the existing model"
      ],
      "metadata": {
        "id": "xRi45YNoJb29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pt_model_new = AutoModelForSequenceClassification.from_pretrained(\"./data\")\n",
        "pt_tokenizer_new = AutoTokenizer.from_pretrained(\"./data\", form_tf=True)\n",
        "pt_output_model = pt_model(**pt_batch)\n",
        "print(pt_output_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diqjgOrqItYh",
        "outputId": "ca7fc4cc-6225-4838-9aa1-ffe8755af3e4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SequenceClassifierOutput(loss=None, logits=tensor([[-1.1220, -1.6687, -0.5555,  0.6776,  2.1259],\n",
            "        [-0.4588, -0.6722, -0.1753,  0.2649,  0.6359]],\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fd1hNZF3JTlP"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jzujaq1uK3nZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}